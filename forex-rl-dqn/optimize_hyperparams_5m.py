#!/usr/bin/env python3
"""
Script de Otimiza√ß√£o de Hiperpar√¢metros para USDJPY 5m.

Este script testa diferentes combina√ß√µes de:
- Features t√©cnicas (RSI, EMA, MACD, Bollinger, ATR, etc.)
- Hiperpar√¢metros do LightGBM (learning_rate, num_leaves, max_depth, etc.)
- Prediction horizon

Salva os resultados em CSV e identifica a melhor combina√ß√£o.
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np
import yaml
import logging
from datetime import datetime
from itertools import product
import json
from copy import deepcopy
from typing import Dict

# Adiciona path raiz
root_dir = Path(__file__).parent
sys.path.insert(0, str(root_dir))

from src.training.train_lightgbm import train_lightgbm

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class HyperparameterOptimizer:
    """Otimizador de hiperpar√¢metros para LightGBM Forex."""
    
    def __init__(self, base_config_path: str, output_dir: str = "optimization_results"):
        """
        Inicializa otimizador.
        
        Args:
            base_config_path: Caminho para config base
            output_dir: Diret√≥rio para salvar resultados
        """
        self.base_config_path = base_config_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Carrega config base
        with open(base_config_path, 'r') as f:
            self.base_config = yaml.safe_load(f)
        
        self.results = []
        self.best_result = None
        
    def define_search_space(self):
        """
        Define espa√ßo de busca de hiperpar√¢metros.
        
        Returns:
            Dict com par√¢metros a testar
        """
        search_space = {
            # === FEATURES ===
            'features': [
                # Combina√ß√µes de features
                {'use_ema': True, 'use_macd': True, 'use_rsi': False, 'use_bollinger': False, 'use_atr': True},
                {'use_ema': True, 'use_macd': True, 'use_rsi': True, 'use_bollinger': True, 'use_atr': True},
                {'use_ema': True, 'use_macd': False, 'use_rsi': True, 'use_bollinger': True, 'use_atr': True},
                {'use_ema': True, 'use_macd': True, 'use_rsi': True, 'use_bollinger': False, 'use_atr': False},
                {'use_ema': False, 'use_macd': False, 'use_rsi': True, 'use_bollinger': True, 'use_atr': True},
            ],
            
            # === PREDICTION HORIZON ===
            # Para 5m: 3 = 15min, 6 = 30min, 12 = 60min (1h)
            'prediction_horizon': [3, 6, 9, 12],
            
            # === LIGHTGBM PARAMS ===
            'learning_rate': [0.01, 0.03, 0.05],
            'num_leaves': [31, 50, 70],
            'max_depth': [4, 6, 8],
            'n_estimators': [300, 500, 800],
            'min_child_samples': [10, 20, 30],
            'subsample': [0.7, 0.8, 0.9],
            'colsample_bytree': [0.7, 0.8, 0.9],
            'reg_alpha': [0.1, 0.3, 0.5],
            'reg_lambda': [0.1, 0.3, 0.5],
        }
        
        return search_space
    
    def generate_combinations(self, max_combinations: int = 100):
        """
        Gera combina√ß√µes de hiperpar√¢metros para testar.
        
        Args:
            max_combinations: N√∫mero m√°ximo de combina√ß√µes
            
        Returns:
            Lista de dicts com combina√ß√µes
        """
        search_space = self.define_search_space()
        
        # Estrat√©gia: Random Search (mais eficiente que Grid Search)
        combinations = []
        
        # Primeiro testa todas as combina√ß√µes de features com params padr√£o
        for features in search_space['features']:
            combo = {
                'features': features,
                'prediction_horizon': 6,  # padr√£o para 5m (30 min √† frente)
                'learning_rate': 0.03,
                'num_leaves': 50,
                'max_depth': 6,
                'n_estimators': 500,
                'min_child_samples': 20,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'reg_alpha': 0.3,
                'reg_lambda': 0.3,
            }
            combinations.append(combo)
        
        # Depois faz random search dos outros par√¢metros
        np.random.seed(42)
        num_feature_combos = len(search_space['features'])
        
        for i in range(max_combinations - len(combinations)):
            # Seleciona features aleatoriamente pelo √≠ndice
            feature_idx = np.random.randint(0, num_feature_combos)
            
            combo = {
                'features': search_space['features'][feature_idx],
                'prediction_horizon': int(np.random.choice(search_space['prediction_horizon'])),  # Converte para int Python
                'learning_rate': float(np.random.choice(search_space['learning_rate'])),  # Converte para float Python
                'num_leaves': int(np.random.choice(search_space['num_leaves'])),
                'max_depth': int(np.random.choice(search_space['max_depth'])),
                'n_estimators': int(np.random.choice(search_space['n_estimators'])),
                'min_child_samples': int(np.random.choice(search_space['min_child_samples'])),
                'subsample': float(np.random.choice(search_space['subsample'])),
                'colsample_bytree': float(np.random.choice(search_space['colsample_bytree'])),
                'reg_alpha': float(np.random.choice(search_space['reg_alpha'])),
                'reg_lambda': float(np.random.choice(search_space['reg_lambda'])),
            }
            combinations.append(combo)
        
        logger.info(f"Geradas {len(combinations)} combina√ß√µes para testar")
        return combinations
    
    def create_config_from_combination(self, combination: dict) -> dict:
        """
        Cria config a partir de uma combina√ß√£o de hiperpar√¢metros.
        
        Args:
            combination: Dict com hiperpar√¢metros
            
        Returns:
            Config completo
        """
        config = deepcopy(self.base_config)  # Deep copy para n√£o modificar original
        
        # Atualiza features
        for key, value in combination['features'].items():
            if key in config['features']:
                config['features'][key] = value
        
        # Atualiza prediction horizon
        config['lightgbm']['prediction_horizon'] = combination['prediction_horizon']
        
        # Atualiza params LightGBM
        lgbm_params = [
            'learning_rate', 'num_leaves', 'max_depth', 'n_estimators',
            'min_child_samples', 'subsample', 'colsample_bytree',
            'reg_alpha', 'reg_lambda'
        ]
        
        for param in lgbm_params:
            if param in combination:
                config['lightgbm']['params'][param] = combination[param]
        
        return config
    
    def evaluate_combination(self, combination: dict, index: int, total: int) -> dict:
        """
        Treina e avalia uma combina√ß√£o de hiperpar√¢metros.
        
        Args:
            combination: Dict com hiperpar√¢metros
            index: √çndice da combina√ß√£o
            total: Total de combina√ß√µes
            
        Returns:
            Dict com resultados
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"TESTANDO COMBINA√á√ÉO {index+1}/{total}")
        logger.info(f"{'='*80}")
        
        # Cria config
        config = self.create_config_from_combination(combination)
        
        # Salva config tempor√°rio
        temp_config_path = self.output_dir / f"temp_config_{index}.yaml"
        with open(temp_config_path, 'w') as f:
            yaml.dump(config, f)
        
        try:
            # Treina modelo
            result = train_lightgbm(str(temp_config_path))
            
            # Extrai m√©tricas
            metrics = result['metrics']
            
            # Verifica se √© regress√£o ou classifica√ß√£o
            is_regression = 'rmse' in metrics.get('train', {})
            
            # Resultado consolidado
            eval_result = {
                'combination_id': index,
                'timestamp': datetime.now().isoformat(),
                
                # Features
                'use_ema': combination['features'].get('use_ema', False),
                'use_macd': combination['features'].get('use_macd', False),
                'use_rsi': combination['features'].get('use_rsi', False),
                'use_bollinger': combination['features'].get('use_bollinger', False),
                'use_atr': combination['features'].get('use_atr', False),
                
                # Hiperpar√¢metros
                'prediction_horizon': combination['prediction_horizon'],
                'learning_rate': combination['learning_rate'],
                'num_leaves': combination['num_leaves'],
                'max_depth': combination['max_depth'],
                'n_estimators': combination['n_estimators'],
                'min_child_samples': combination['min_child_samples'],
                'subsample': combination['subsample'],
                'colsample_bytree': combination['colsample_bytree'],
                'reg_alpha': combination['reg_alpha'],
                'reg_lambda': combination['reg_lambda'],
            }
            
            # Adiciona m√©tricas conforme o tipo de modelo
            if is_regression:
                # M√©tricas de treino
                eval_result['train_rmse'] = metrics['train']['rmse']
                eval_result['train_mae'] = metrics['train']['mae']
                eval_result['train_r2'] = metrics['train']['r2']
                eval_result['train_direction_acc'] = metrics['train']['direction_accuracy']
                
                # M√©tricas de valida√ß√£o
                eval_result['val_rmse'] = metrics['val']['rmse']
                eval_result['val_mae'] = metrics['val']['mae']
                eval_result['val_r2'] = metrics['val']['r2']
                eval_result['val_direction_acc'] = metrics['val']['direction_accuracy']
                
                # M√©tricas de teste
                eval_result['test_rmse'] = metrics['test']['rmse']
                eval_result['test_mae'] = metrics['test']['mae']
                eval_result['test_r2'] = metrics['test']['r2']
                eval_result['test_direction_acc'] = metrics['test']['direction_accuracy']
                
                # Score combinado (menor √© melhor)
                eval_result['combined_score'] = metrics['test']['rmse'] + (1 - metrics['test']['direction_accuracy'])
            else:
                # M√©tricas de classifica√ß√£o
                eval_result['train_accuracy'] = metrics['train'].get('accuracy', 0)
                eval_result['train_direction_acc'] = metrics['train'].get('accuracy', 0)
                eval_result['val_accuracy'] = metrics['val'].get('accuracy', 0)
                eval_result['val_direction_acc'] = metrics['val'].get('accuracy', 0)
                eval_result['test_accuracy'] = metrics['test'].get('accuracy', 0)
                eval_result['test_direction_acc'] = metrics['test'].get('accuracy', 0)
                eval_result['combined_score'] = 1 - metrics['test'].get('accuracy', 0)
            
            logger.info(f"‚úÖ RESULTADO:")
            logger.info(f"   Test RMSE: {eval_result['test_rmse']:.6f}")
            logger.info(f"   Test Direction Acc: {eval_result['test_direction_acc']:.4f}")
            logger.info(f"   Combined Score: {eval_result['combined_score']:.6f}")
            
            return eval_result
            
        except Exception as e:
            logger.error(f"‚ùå ERRO ao treinar combina√ß√£o {index}: {e}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return None
            
        finally:
            # Remove config tempor√°rio
            if temp_config_path.exists():
                temp_config_path.unlink()
    
    def run_optimization(self, max_combinations: int = 100):
        """
        Executa otimiza√ß√£o de hiperpar√¢metros.
        
        Args:
            max_combinations: N√∫mero m√°ximo de combina√ß√µes a testar
        """
        logger.info(f"üöÄ Iniciando otimiza√ß√£o de hiperpar√¢metros - USDJPY 5m")
        logger.info(f"   Base config: {self.base_config_path}")
        logger.info(f"   Output dir: {self.output_dir}")
        logger.info(f"   Max combinations: {max_combinations}")
        
        # Gera combina√ß√µes
        combinations = self.generate_combinations(max_combinations)
        
        # Testa cada combina√ß√£o
        successful = 0
        failed = 0
        
        for i, combination in enumerate(combinations):
            logger.info(f"\n{'='*80}")
            logger.info(f"PROGRESSO: {i+1}/{len(combinations)} ({(i+1)/len(combinations)*100:.1f}%)")
            logger.info(f"Sucessos: {successful}, Falhas: {failed}")
            logger.info(f"{'='*80}")
            
            result = self.evaluate_combination(combination, i, len(combinations))
            
            if result is not None:
                self.results.append(result)
                successful += 1
                
                # Atualiza melhor resultado
                if self.best_result is None or result['combined_score'] < self.best_result['combined_score']:
                    self.best_result = result
                    logger.info(f"üèÜ NOVO MELHOR RESULTADO! Score: {result['combined_score']:.6f}")
            else:
                failed += 1
                logger.warning(f"‚ö†Ô∏è  Combina√ß√£o {i} falhou!")
                
            # Salva resultados parciais a cada 5 itera√ß√µes
            if (i + 1) % 5 == 0:
                self.save_results()
                logger.info(f"üíæ Resultados parciais salvos ({len(self.results)} combina√ß√µes bem-sucedidas)")
        
        logger.info(f"\n{'='*80}")
        logger.info(f"FINALIZA√á√ÉO")
        logger.info(f"Total testado: {len(combinations)}")
        logger.info(f"Sucessos: {successful}")
        logger.info(f"Falhas: {failed}")
        logger.info(f"{'='*80}")
        
        # Salva resultados finais
        self.save_results()
        
        # Mostra resumo
        self.print_summary()
    
    def save_results(self):
        """Salva resultados em CSV e JSON."""
        if not self.results:
            return
        
        # CSV com todos os resultados
        df = pd.DataFrame(self.results)
        csv_path = self.output_dir / "optimization_results.csv"
        df.to_csv(csv_path, index=False)
        logger.info(f"üíæ Resultados salvos em: {csv_path}")
        
        # JSON com melhor resultado
        if self.best_result:
            json_path = self.output_dir / "best_config.json"
            with open(json_path, 'w') as f:
                json.dump(self.best_result, f, indent=2)
            logger.info(f"üèÜ Melhor config salvo em: {json_path}")
    
    def print_summary(self):
        """Imprime resumo da otimiza√ß√£o."""
        if not self.results:
            logger.warning("Nenhum resultado dispon√≠vel")
            return
        
        df = pd.DataFrame(self.results)
        
        logger.info(f"\n{'='*80}")
        logger.info(f"RESUMO DA OTIMIZA√á√ÉO - USDJPY 5m")
        logger.info(f"{'='*80}")
        logger.info(f"Total de combina√ß√µes testadas: {len(self.results)}")
        logger.info(f"\nEstat√≠sticas (Test Set):")
        logger.info(f"  RMSE - Min: {df['test_rmse'].min():.6f}, Max: {df['test_rmse'].max():.6f}, M√©dia: {df['test_rmse'].mean():.6f}")
        logger.info(f"  Direction Acc - Min: {df['test_direction_acc'].min():.4f}, Max: {df['test_direction_acc'].max():.4f}, M√©dia: {df['test_direction_acc'].mean():.4f}")
        
        logger.info(f"\n{'='*80}")
        logger.info(f"üèÜ MELHOR CONFIGURA√á√ÉO")
        logger.info(f"{'='*80}")
        
        best = self.best_result
        logger.info(f"Combined Score: {best['combined_score']:.6f}")
        logger.info(f"\nFeatures:")
        logger.info(f"  EMA: {best['use_ema']}, MACD: {best['use_macd']}, RSI: {best['use_rsi']}")
        logger.info(f"  Bollinger: {best['use_bollinger']}, ATR: {best['use_atr']}")
        
        logger.info(f"\nHiperpar√¢metros:")
        logger.info(f"  Prediction Horizon: {best['prediction_horizon']} candles ({best['prediction_horizon'] * 5} min)")
        logger.info(f"  Learning Rate: {best['learning_rate']}")
        logger.info(f"  Num Leaves: {best['num_leaves']}")
        logger.info(f"  Max Depth: {best['max_depth']}")
        logger.info(f"  N Estimators: {best['n_estimators']}")
        
        logger.info(f"\nM√©tricas (Test Set):")
        logger.info(f"  RMSE: {best['test_rmse']:.6f}")
        logger.info(f"  MAE: {best['test_mae']:.6f}")
        logger.info(f"  R¬≤: {best['test_r2']:.6f}")
        logger.info(f"  Direction Accuracy: {best['test_direction_acc']:.4f}")
        
        # Top 5 melhores
        logger.info(f"\n{'='*80}")
        logger.info(f"TOP 5 MELHORES COMBINA√á√ïES")
        logger.info(f"{'='*80}")
        
        top5 = df.nsmallest(5, 'combined_score')
        for idx, row in top5.iterrows():
            logger.info(f"\n#{idx+1}:")
            logger.info(f"  Score: {row['combined_score']:.6f}")
            logger.info(f"  Test RMSE: {row['test_rmse']:.6f}, Direction Acc: {row['test_direction_acc']:.4f}")
            logger.info(f"  Features: EMA={row['use_ema']}, MACD={row['use_macd']}, RSI={row['use_rsi']}")
            logger.info(f"  LR={row['learning_rate']}, Leaves={row['num_leaves']}, Depth={row['max_depth']}")
        
        # Gera relat√≥rio detalhado em TXT
        self._generate_detailed_report(best, top5)
    
    def _generate_detailed_report(self, best: Dict, top5: pd.DataFrame):
        """Gera relat√≥rio detalhado em TXT explicando o melhor resultado."""
        report_path = os.path.join(self.output_dir, 'best_result_explained.txt')
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("RELAT√ìRIO DE OTIMIZA√á√ÉO - USDJPY 5m\n")
            f.write(f"Data: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("="*80 + "\n\n")
            
            f.write("MELHOR CONFIGURA√á√ÉO ENCONTRADA\n")
            f.write("-"*80 + "\n\n")
            
            # M√©tricas de Performance
            f.write("1. M√âTRICAS DE PERFORMANCE (Test Set)\n\n")
            f.write(f"   Score Combinado: {best['combined_score']:.6f}\n")
            f.write(f"   - Quanto menor, melhor (combina RMSE e erro de dire√ß√£o)\n\n")
            
            f.write(f"   RMSE (Root Mean Square Error): {best['test_rmse']:.6f}\n")
            f.write(f"   - Erro m√©dio quadr√°tico das previs√µes de pre√ßo\n")
            f.write(f"   - Quanto menor, mais preciso √© o modelo\n\n")
            
            f.write(f"   MAE (Mean Absolute Error): {best['test_mae']:.6f}\n")
            f.write(f"   - Erro m√©dio absoluto das previs√µes\n")
            f.write(f"   - Interpreta√ß√£o: em m√©dia, previs√µes erram por {best['test_mae']:.6f} pips\n\n")
            
            f.write(f"   R¬≤ (Coeficiente de Determina√ß√£o): {best['test_r2']:.6f}\n")
            f.write(f"   - Explica {best['test_r2']*100:.2f}% da vari√¢ncia dos pre√ßos\n")
            f.write(f"   - Valores pr√≥ximos de 1 s√£o melhores\n\n")
            
            f.write(f"   Acur√°cia Direcional: {best['test_direction_acc']:.4f} ({best['test_direction_acc']*100:.2f}%)\n")
            f.write(f"   - Percentual de vezes que prev√™ corretamente se o pre√ßo vai subir ou descer\n")
            f.write(f"   - Crucial para trading: acima de 50% indica poder preditivo\n\n")
            
            # Features Ativadas
            f.write("2. FEATURES/INDICADORES T√âCNICOS ATIVADOS\n\n")
            
            features_info = [
                ('use_rsi', 'RSI (Relative Strength Index)', 'Identifica condi√ß√µes de sobrecompra/sobrevenda'),
                ('use_ema', 'EMA (Exponential Moving Average)', 'Suaviza tend√™ncias de pre√ßo'),
                ('use_macd', 'MACD (Moving Average Convergence Divergence)', 'Detecta mudan√ßas de momentum'),
                ('use_stochastic', 'Stochastic Oscillator', 'Mede momentum comparando pre√ßo de fechamento com range'),
                ('use_adx', 'ADX (Average Directional Index)', 'Mede for√ßa da tend√™ncia'),
                ('use_cci', 'CCI (Commodity Channel Index)', 'Identifica n√≠veis c√≠clicos'),
                ('use_williams', 'Williams %R', 'Oscilador de momentum para sobrecompra/sobrevenda'),
                ('use_roc', 'ROC (Rate of Change)', 'Velocidade de mudan√ßa de pre√ßo'),
                ('use_obv', 'OBV (On-Balance Volume)', 'Relaciona volume com movimento de pre√ßo'),
                ('use_mfi', 'MFI (Money Flow Index)', 'RSI ponderado por volume'),
                ('use_bollinger', 'Bollinger Bands', 'Bandas de volatilidade'),
                ('use_atr', 'ATR (Average True Range)', 'Mede volatilidade do mercado'),
            ]
            
            for key, name, desc in features_info:
                # Usa .get() para lidar com features que podem n√£o estar no CSV
                is_active = best.get(key, False)
                status = "‚úì ATIVO" if is_active else "‚úó Desativado"
                f.write(f"   {status:15} {name:45} - {desc}\n")
            
            # Hiperpar√¢metros
            f.write("\n3. HIPERPAR√ÇMETROS DO LIGHTGBM\n\n")
            
            f.write(f"   Prediction Horizon: {int(best['prediction_horizon'])}\n")
            f.write(f"   - Quantos candles √† frente o modelo prev√™\n")
            f.write(f"   - Valor {int(best['prediction_horizon'])} = prev√™ {int(best['prediction_horizon']) * 5} minutos √† frente\n\n")
            
            f.write(f"   Learning Rate: {best['learning_rate']}\n")
            f.write(f"   - Taxa de aprendizado do modelo\n")
            f.write(f"   - Valores menores = aprendizado mais lento mas est√°vel\n\n")
            
            f.write(f"   Num Leaves: {int(best['num_leaves'])}\n")
            f.write(f"   - N√∫mero m√°ximo de folhas nas √°rvores\n")
            f.write(f"   - Controla complexidade: mais folhas = modelo mais complexo\n\n")
            
            f.write(f"   Max Depth: {int(best['max_depth'])}\n")
            f.write(f"   - Profundidade m√°xima das √°rvores\n")
            f.write(f"   - Limita crescimento para evitar overfitting\n\n")
            
            f.write(f"   N Estimators: {int(best['n_estimators'])}\n")
            f.write(f"   - N√∫mero de √°rvores no ensemble\n")
            f.write(f"   - Mais √°rvores = modelo mais robusto (at√© certo ponto)\n\n")
            
            f.write(f"   Min Child Samples: {int(best['min_child_samples'])}\n")
            f.write(f"   - M√≠nimo de amostras para criar uma folha\n")
            f.write(f"   - Previne overfitting em regi√µes com poucos dados\n\n")
            
            f.write(f"   Subsample: {best['subsample']}\n")
            f.write(f"   - Fra√ß√£o de dados usada para treinar cada √°rvore\n")
            f.write(f"   - Adiciona randomiza√ß√£o para melhorar generaliza√ß√£o\n\n")
            
            f.write(f"   Colsample Bytree: {best['colsample_bytree']}\n")
            f.write(f"   - Fra√ß√£o de features usadas em cada √°rvore\n")
            f.write(f"   - Reduz correla√ß√£o entre √°rvores\n\n")
            
            f.write(f"   Reg Alpha: {best['reg_alpha']}\n")
            f.write(f"   - Regulariza√ß√£o L1 (Lasso)\n")
            f.write(f"   - Penaliza features menos importantes\n\n")
            
            f.write(f"   Reg Lambda: {best['reg_lambda']}\n")
            f.write(f"   - Regulariza√ß√£o L2 (Ridge)\n")
            f.write(f"   - Suaviza pesos para evitar overfitting\n\n")
            
            # Top 5 alternativas
            f.write("="*80 + "\n")
            f.write("TOP 5 MELHORES CONFIGURA√á√ïES\n")
            f.write("="*80 + "\n\n")
            
            for idx, (_, row) in enumerate(top5.iterrows(), 1):
                f.write(f"#{idx} - Score: {row['combined_score']:.6f}\n")
                f.write(f"   M√©tricas: RMSE={row['test_rmse']:.6f}, MAE={row['test_mae']:.6f}, "
                       f"R¬≤={row['test_r2']:.6f}, Dir Acc={row['test_direction_acc']:.4f}\n")
                f.write(f"   Features: RSI={row.get('use_rsi', False)}, EMA={row.get('use_ema', False)}, MACD={row.get('use_macd', False)}, "
                       f"Bollinger={row.get('use_bollinger', False)}, ATR={row.get('use_atr', False)}\n")
                f.write(f"   Hiperpar√¢metros: LR={row['learning_rate']}, Leaves={int(row['num_leaves'])}, "
                       f"Depth={int(row['max_depth'])}, N_Est={int(row['n_estimators'])}\n")
                f.write(f"   Horizon={int(row['prediction_horizon'])} ({int(row['prediction_horizon']) * 5}min), Subsample={row['subsample']}, "
                       f"Colsample={row['colsample_bytree']}\n\n")
            
            # Interpreta√ß√£o e recomenda√ß√µes
            f.write("="*80 + "\n")
            f.write("INTERPRETA√á√ÉO E RECOMENDA√á√ïES\n")
            f.write("="*80 + "\n\n")
            
            f.write("COMO USAR ESTA CONFIGURA√á√ÉO:\n\n")
            f.write("1. O arquivo 'best_config.yaml' j√° foi gerado com estes par√¢metros\n")
            f.write("2. Use-o para treinar o modelo final: python -m src.rl.train --config best_config.yaml\n")
            f.write("3. A acur√°cia direcional √© o principal indicador para trading\n")
            f.write("4. Valores acima de 55% de acur√°cia direcional j√° s√£o √∫teis em produ√ß√£o\n\n")
            
            f.write("PR√ìXIMOS PASSOS:\n\n")
            f.write("1. Treinar modelo completo com a melhor configura√ß√£o\n")
            f.write("2. Fazer backtesting em dados out-of-sample\n")
            f.write("3. Validar performance em diferentes condi√ß√µes de mercado\n")
            f.write("4. Monitorar drift: performance pode degradar ao longo do tempo\n")
            f.write("5. Considerar re-treinamento peri√≥dico (ex: semanal/quinzenal para 5m)\n\n")
            
            f.write("OBSERVA√á√ïES ESPEC√çFICAS PARA 5m:\n\n")
            f.write("- Timeframe mais r√°pido = mais ru√≠do no mercado\n")
            f.write("- Requer gest√£o de risco mais rigorosa devido √† maior frequ√™ncia de sinais\n")
            f.write("- Spread e custos de transa√ß√£o t√™m impacto maior em 5m\n")
            f.write("- Considere filtros adicionais para reduzir falsos sinais\n\n")
            
            if best['test_direction_acc'] < 0.52:
                f.write("‚ö†Ô∏è  AVISO: Acur√°cia direcional abaixo de 52%\n")
                f.write("   - Modelo tem baixo poder preditivo\n")
                f.write("   - Recomenda-se coletar mais dados ou testar outras features\n")
                f.write("   - Em 5m, considere usar timeframes maiores para confirma√ß√£o\n\n")
            elif best['test_direction_acc'] < 0.55:
                f.write("‚ö° ATEN√á√ÉO: Acur√°cia direcional moderada (52-55%)\n")
                f.write("   - Modelo pode ser √∫til mas requer gest√£o de risco cuidadosa\n")
                f.write("   - Considere combinar com outros sinais/filtros\n")
                f.write("   - Use stop loss apertado devido √† volatilidade do 5m\n\n")
            else:
                f.write("‚úì EXCELENTE: Acur√°cia direcional acima de 55%\n")
                f.write("   - Modelo demonstra bom poder preditivo\n")
                f.write("   - Adequado para uso em trading com gest√£o de risco apropriada\n")
                f.write("   - Ainda assim, valide em paper trading antes de usar capital real\n\n")
        
        logger.info(f"\nüìÑ Relat√≥rio detalhado salvo em: {report_path}")


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Otimiza√ß√£o de hiperpar√¢metros para LightGBM - USDJPY 5m')
    parser.add_argument(
        '--config',
        type=str,
        default='config_hybrid_5m.yaml',
        help='Path para config base'
    )
    parser.add_argument(
        '--output-dir',
        type=str,
        default='optimization_results/usdjpy_5m',
        help='Diret√≥rio para salvar resultados'
    )
    parser.add_argument(
        '--max-combinations',
        type=int,
        default=50,
        help='N√∫mero m√°ximo de combina√ß√µes a testar'
    )
    
    args = parser.parse_args()
    
    # Cria otimizador
    optimizer = HyperparameterOptimizer(
        base_config_path=args.config,
        output_dir=args.output_dir
    )
    
    # Executa otimiza√ß√£o
    optimizer.run_optimization(max_combinations=args.max_combinations)
    
    logger.info("\n‚úÖ Otimiza√ß√£o conclu√≠da!")
